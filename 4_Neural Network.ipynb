{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-d0536b95eb5b>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Neural Network Parameters\n",
    "n_hidden_1 = 392\n",
    "n_hidden_2 = 256\n",
    "n_feature = 784\n",
    "n_classes = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X : Tensor(\"image_features:0\", shape=(?, 784), dtype=float32)\n",
      "Y : Tensor(\"labels:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None, n_feature], name='image_features')\n",
    "Y = tf.placeholder('float', [None, n_classes], name='labels')\n",
    "print(\"X :\", X)\n",
    "print(\"Y :\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "weights = {'w1': tf.Variable(tf.random_normal([n_feature, n_hidden_1])),\n",
    "           'w2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "           'w_out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))}\n",
    "biases = {'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "          'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "          'b_out': tf.Variable(tf.random_normal([n_classes]))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights   =>    {'w1': <tf.Variable 'Variable:0' shape=(784, 392) dtype=float32_ref>, 'w2': <tf.Variable 'Variable_1:0' shape=(392, 256) dtype=float32_ref>, 'w_out': <tf.Variable 'Variable_2:0' shape=(256, 10) dtype=float32_ref>}\n",
      "biases     =>    {'b1': <tf.Variable 'Variable_3:0' shape=(392,) dtype=float32_ref>, 'b2': <tf.Variable 'Variable_4:0' shape=(256,) dtype=float32_ref>, 'b_out': <tf.Variable 'Variable_5:0' shape=(10,) dtype=float32_ref>}\n"
     ]
    }
   ],
   "source": [
    "print(\"weights   =>   \", weights)\n",
    "print(\"biases     =>   \", biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-8170402c613a>:11: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# forward\n",
    "def neural_network(x):\n",
    "    layer1 = tf.add(tf.matmul(x,weights['w1']),biases['b1']) # layer 1 = 1x392\n",
    "    layer2 = tf.add(tf.matmul(layer1,weights['w2']),biases['b2']) # Layer 2 = 1x256\n",
    "    out_layer = tf.add(tf.matmul(layer2,weights['w_out']),biases['b_out']) # out_layer = 1x10\n",
    "    return out_layer\n",
    "\n",
    "logits = neural_network(X) # X = 15*784 -> logit = 15*10 -> \n",
    "\n",
    "# Compute loss and optimizer\n",
    "loss_op =tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels= Y))\n",
    "# backwark\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1)  \n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate models \n",
    "correct_pred = tf.equal(tf.argmax(logits,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 22356.611328125\n",
      "Epoch: 0002 cost= 17942.232421875\n",
      "Epoch: 0003 cost= 20631.224609375\n",
      "Epoch: 0004 cost= 25383.718750000\n",
      "Epoch: 0005 cost= 14429.401367188\n",
      "Epoch: 0006 cost= 6962.776855469\n",
      "Epoch: 0007 cost= 8656.952148438\n",
      "Epoch: 0008 cost= 7682.372070312\n",
      "Epoch: 0009 cost= 5840.162597656\n",
      "Epoch: 0010 cost= 5555.145019531\n",
      "Epoch: 0011 cost= 4342.921386719\n",
      "Epoch: 0012 cost= 3691.211669922\n",
      "Epoch: 0013 cost= 4007.921630859\n",
      "Epoch: 0014 cost= 3702.884765625\n",
      "Epoch: 0015 cost= 3496.976806641\n",
      "Epoch: 0016 cost= 3285.340820312\n",
      "Epoch: 0017 cost= 3016.093994141\n",
      "Epoch: 0018 cost= 2827.676757812\n",
      "Epoch: 0019 cost= 2749.704589844\n",
      "Epoch: 0020 cost= 2478.308105469\n",
      "Epoch: 0021 cost= 2471.728515625\n",
      "Epoch: 0022 cost= 2212.825683594\n",
      "Epoch: 0023 cost= 2125.299560547\n",
      "Epoch: 0024 cost= 2006.298828125\n",
      "Epoch: 0025 cost= 1855.279418945\n",
      "Epoch: 0026 cost= 1669.106201172\n",
      "Epoch: 0027 cost= 1708.439208984\n",
      "Epoch: 0028 cost= 1603.270507812\n",
      "Epoch: 0029 cost= 1594.173095703\n",
      "Epoch: 0030 cost= 1458.330078125\n",
      "Epoch: 0031 cost= 1289.706787109\n",
      "Epoch: 0032 cost= 1339.267333984\n",
      "Epoch: 0033 cost= 1183.266601562\n",
      "Epoch: 0034 cost= 1106.612548828\n",
      "Epoch: 0035 cost= 1029.940185547\n",
      "Epoch: 0036 cost= 1180.941406250\n",
      "Epoch: 0037 cost= 1094.358886719\n",
      "Epoch: 0038 cost= 946.787170410\n",
      "Epoch: 0039 cost= 946.329528809\n",
      "Epoch: 0040 cost= 850.100280762\n",
      "Epoch: 0041 cost= 952.425292969\n",
      "Epoch: 0042 cost= 782.080444336\n",
      "Epoch: 0043 cost= 695.243652344\n",
      "Epoch: 0044 cost= 726.387634277\n",
      "Epoch: 0045 cost= 666.428894043\n",
      "Epoch: 0046 cost= 668.244323730\n",
      "Epoch: 0047 cost= 667.678588867\n",
      "Epoch: 0048 cost= 680.058471680\n",
      "Epoch: 0049 cost= 672.776794434\n",
      "Epoch: 0050 cost= 576.034484863\n",
      "Epoch: 0051 cost= 542.894775391\n",
      "Epoch: 0052 cost= 544.538024902\n",
      "Epoch: 0053 cost= 532.333923340\n",
      "Epoch: 0054 cost= 508.734313965\n",
      "Epoch: 0055 cost= 495.867858887\n",
      "Epoch: 0056 cost= 490.172210693\n",
      "Epoch: 0057 cost= 465.370513916\n",
      "Epoch: 0058 cost= 423.282958984\n",
      "Epoch: 0059 cost= 471.065948486\n",
      "Epoch: 0060 cost= 413.694305420\n",
      "Epoch: 0061 cost= 397.858337402\n",
      "Epoch: 0062 cost= 398.911163330\n",
      "Epoch: 0063 cost= 373.464843750\n",
      "Epoch: 0064 cost= 328.141906738\n",
      "Epoch: 0065 cost= 350.073638916\n",
      "Epoch: 0066 cost= 342.189910889\n",
      "Epoch: 0067 cost= 319.433563232\n",
      "Epoch: 0068 cost= 322.101348877\n",
      "Epoch: 0069 cost= 322.708435059\n",
      "Epoch: 0070 cost= 279.893402100\n",
      "Epoch: 0071 cost= 304.838806152\n",
      "Epoch: 0072 cost= 278.068695068\n",
      "Epoch: 0073 cost= 249.103256226\n",
      "Epoch: 0074 cost= 276.966949463\n",
      "Epoch: 0075 cost= 257.117187500\n",
      "Epoch: 0076 cost= 257.391204834\n",
      "Epoch: 0077 cost= 252.776702881\n",
      "Epoch: 0078 cost= 254.224899292\n",
      "Epoch: 0079 cost= 223.221496582\n",
      "Epoch: 0080 cost= 224.346221924\n",
      "Epoch: 0081 cost= 217.475692749\n",
      "Epoch: 0082 cost= 208.006103516\n",
      "Epoch: 0083 cost= 191.056655884\n",
      "Epoch: 0084 cost= 188.048599243\n",
      "Epoch: 0085 cost= 176.305603027\n",
      "Epoch: 0086 cost= 200.414123535\n",
      "Epoch: 0087 cost= 200.972030640\n",
      "Epoch: 0088 cost= 191.802459717\n",
      "Epoch: 0089 cost= 173.711227417\n",
      "Epoch: 0090 cost= 175.326293945\n",
      "Epoch: 0091 cost= 175.142532349\n",
      "Epoch: 0092 cost= 153.909378052\n",
      "Epoch: 0093 cost= 157.014999390\n",
      "Epoch: 0094 cost= 150.890365601\n",
      "Epoch: 0095 cost= 162.429382324\n",
      "Epoch: 0096 cost= 138.175262451\n",
      "Epoch: 0097 cost= 136.306869507\n",
      "Epoch: 0098 cost= 147.324874878\n",
      "Epoch: 0099 cost= 143.802810669\n",
      "Epoch: 0100 cost= 134.666717529\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9091\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "training_epochs = 100\n",
    "\n",
    "tf.summary.scalar(\"loss_show\", loss_op)\n",
    "tf.summary.scalar(\"accuracy_show\", accuracy)\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    summary_writer = tf.summary.FileWriter(logdir='./logdir2', graph=tf.get_default_graph())\n",
    "    for epoch in range(training_epochs):\n",
    "        # 1 iterator\n",
    "        #print(sess.run(loss_op))\n",
    "        image_batch, label_batch = mnist.train.next_batch(10000)\n",
    "        sess.run(train_op, feed_dict={X: image_batch, Y: label_batch})\n",
    "#         sess.run(train_op, feed_dict={X: mnist.train.images, Y: mnist.train.labels})\n",
    "        #Display logs per epoch step\n",
    "        #if (epoch+1) % 10 == 0:\n",
    "        loss, summary = sess.run([loss_op, merged_summary_op], feed_dict={X: image_batch, Y: label_batch})\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(loss))\n",
    "        summary_writer.add_summary(summary,epoch)\n",
    "    print(\"Optimization Finished!\")\n",
    "    print (\"Accuracy:\", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))\n",
    "    \n",
    "\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
